{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- In Python werden DataFrames nur über Zusatzpackages wie [Pandas](https://pandas.pydata.org/pandas-docs/stable/) - unterstützt. \n",
    "- Pandas ist eines der umfangreichsten Python Pakete.\n",
    "- Beim Webscraping ist Pandas besonders für explorative Qualitätskontrollen der Daten und das abspeichern in gängigen Formaten nützlich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd # import als 'pd' Kürzel für weniger Schreibarbeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Diktionäre innerhalb von Listen können in Pandas über eine einzige Zeile Code in einen Datensatz transformiert werden, wobei die Keys als Spaltenbezeichnungen interpretiert werden. Als Beispiel lesen wir die verarbeiteten Daten aus der Grundlagenchallenge ein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 3] Das System kann den angegebenen Pfad nicht finden: 'D:\\\\datascraping\\\\data'\n",
      "C:\\Users\\ekara\\Documents\\GitHub\\python_data_scraping\\notebooks\n"
     ]
    }
   ],
   "source": [
    "%cd \"D:\\datascraping\\data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'section', 'url', 'title', 'text', 'chars', 'month', 'tags'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('guardian_corona_parsed.json', 'r', encoding = 'utf-8') as f:\n",
    "    guardian = json.load(f)\n",
    "guardian[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(guardian)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ein paar gängige Pandas Befehle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['chars'].describe() # Mittelwert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.section.value_counts()[:5] # Häufigkeitsauszählung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "months = [2, 3] # februar und maerz\n",
    "df[df.month.isin(months)].section.value_counts()[:5] # bedingte Häufigkeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.sort_values('month').head(3) # Sortierung über eine oder mehrere Variablen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.text = df.text.str.lower() # String Funktionen\n",
    "df.text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Über die Pandas [IO Tools](https://pandas.pydata.org/pandas-docs/stable/io.html) können Datensätze in eine Vielzahl von Formaten exportiert werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.to_excel('guardian_corona.xlsx', \n",
    "            encoding = 'utf-8', # Enkodierung\n",
    "            index = False) # Index Spalte entfernen\n",
    "\n",
    "# achtung: excel hat einschraenkungen wie z.b. maximale stringlaengen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('guardian_corona.csv', \n",
    "            encoding = 'utf-8',\n",
    "            index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Und wieder eingelesen werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('guardian_corona.csv',\n",
    "                encoding = 'utf-8')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## API Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Wie API's funktionieren:\n",
    "\n",
    "-  API steht für [Application Programming Interface](https://de.wikipedia.org/wiki/Programmierschnittstelle) (Programmierschnittstelle)\n",
    "- Eine Vielzahl von Organisationen bieten API's an um Daten und Dienste verfügbar zu machen (Google, Facebook, Wikipedia, …)\n",
    "- über API's können **strukturierte** Daten abgegriffen werden (oder gepostet werden, je nach Provider) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Für uns haben API's zwei entscheidende Vorteile:\n",
    "    - Der Zugang ist legal und meist klar definiert (z.B. 10.000 Aufrufe pro Tag)\n",
    "    - Wir müssen keine Scraping Techniken für **unstrukturierte Daten** (z.B. Webseiten) anwenden\n",
    "    - Für einige API's gibt es Python Packages, die den Datenzugang vereinfachen\n",
    "- Nachteile: \n",
    "     - Wir müssen lernen, wie die API funktioniert (einige Dokumentationen sind sehr gut, andere weniger)\n",
    "     - Einige APIs verlangen Authentifizierung und / oder sind nicht kostenlos verfügbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### API Zugriff über Pandas Datareader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Der Pandas Datareader ist eine Zusatzbibliothek, die zunächst installiert werden muss. Über das [magic command](http://ipython.readthedocs.io/en/stable/interactive/magics.html) `!` kann direkt die Shell (Eingabeaufforderung) des Betriebsystems angesprochen werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "!pip install pandas-datareader --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- In der [Dokumentation des Pandas Data Readers](https://pandas-datareader.readthedocs.io/en/latest/remote_data.html#world-bank) ist z.B. beschrieben, wie man Daten aus der [World Bank API](http://data.worldbank.org/) abgreifen kann.\n",
    "- Darüber hinaus können auch Daten von Quandl, OECD, MOEX, Eurostat und anderen Quellen abgegriffen werden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from pandas_datareader import wb # importiert world bank zugang\n",
    "search = wb.search('GDP.*current.*US') # suche nach keywords, ergebnis als data frame\n",
    "search.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Wenn der gesuchte Indikator gefunden wurde, kann der entsprechende Datensatz über die API gezogen werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = wb.download(indicator = 'NY.GDP.MKTP.CD', country = ['DE', 'FR', 'IT'],\n",
    "                start = 2010, end = 2019)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.head(6) # Multi-index Datensatz, GDP in Trillionen USD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Datenverarbeitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Deskriptiva über gruppierten Datensatz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby('country').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Datenstruktur verändern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df.reset_index() # indizes als variablen\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df2.columns = ['country', 'year', 'gdp'] # spalten umbenennen\n",
    "df2.year = df2.year.astype(int) # numerischer jahresindikator\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Datenvisualisierung\n",
    "\n",
    "Um Grafiken innerhalb von Notebooks darzustellen muss zunächst einmalig der Befehl `%matplotlib inline` ausgeführt werden. Das Grafik Package [seaborn](https://seaborn.pydata.org/) kann anschließend für einfache Plots importiert werden. Die wichtigsten Funktionen des Pakets werden in [Online Tutorials](https://seaborn.pydata.org/tutorial.html) erklärt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Seaborn falls notwendig innerhalb eines Notebooks installieren bzw. upgraden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!pip install seaborn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(style = 'whitegrid') # visualisierungsstil anpassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sns.catplot(x = 'year', y = 'gdp', hue = 'country', \n",
    "            data = df2, height = 5, kind = 'point');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sns.barplot(x = 'country', y = 'gdp', data = df2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'country', y  = 'gdp', data = df2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x = 'year', y = 'gdp', hue = 'country', data = df2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Übungsaufgabe 1\n",
    "\n",
    "Sucht euch aus der Worldbank API ein Merkmal, das euch interessiert und zieht die Daten aus der API in einen DataFrame. Verwendet anschließend Deskriptiva und/oder einfache Plots, um die Daten zu betrachten. Speichert den Datensatz anschließend in einem Format eurer Wahl, z.B. `csv`, ab. \n",
    "\n",
    "*Hinweis: Nützlich für die Aufgabe könnten die Dokumentationen für die Plotting Funktionalität von [Seaborn](https://seaborn.pydata.org/tutorial.html) und [Pandas](https://pandas.pydata.org/pandas-docs/stable/visualization.html).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Code Übungsaufgabe 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Die Guardian API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Die [Guardian API](http://open-platform.theguardian.com/explore/) ermöglicht es Metadaten und Volltext zu Artikeln aus der britischen Tageszeitung strukturiert (`JSON`) zu erfassen. \n",
    "- Die API hat verschiedene Endpoints (siehe Dokumentation), wobei wir uns hauptsächlich für `/content` interessieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%cd \"D:\\datascraping\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with open('keys/guardian_api.txt', 'r') as f:\n",
    "    # encoding ist hier nicht relevant\n",
    "    api_key = f.read()\n",
    "print(api_key[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Für die Kommunikation brauchen wir:\n",
    "- die korrekte Basis URL\n",
    "- ein entsprechend den API Vorgaben definiertes Set an Parametern, die bestimmen, was zurückgegeben wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "base = 'http://content.guardianapis.com/search'\n",
    "params = {'api-key': api_key, # API Authorisierung über Key\n",
    "         'q':'volkswagen'} # Suchanfrage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Das Python Package [requests](http://docs.python-requests.org/en/master/) verarbeitet Base URL und Parameter (+ optional Header) automatisch zu einer validen [HTTP](https://de.wikipedia.org/wiki/Hypertext_Transfer_Protocol) Anfrage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "print(base)\n",
    "print(params)\n",
    "r = requests.get(base, params = params)\n",
    "data = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "len(data['response']['results'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Der Python Code konvertiert zu einer URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "r.url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[Status Code](https://de.wikipedia.org/wiki/HTTP-Statuscode) der HTTP Anfrage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "r.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "String Version der API Response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "r.text[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "JSON Version (Diktionär) der API Response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = r.json()\n",
    "data['response'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(data['response']['results'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Übungsaufgabe 2\n",
    "\n",
    "- Wie viele Artikel wurden über die obige Anfrage ausgegeben?\n",
    "- Macht euch mit der [Online Dokumentation](https://open-platform.theguardian.com/documentation/) der API vertraut.\n",
    "    - Findet einen Weg, mehr Artikel pro Anfrage abzurufen\n",
    "    - Findet einen Weg, Artikel Volltexte abzurufen\n",
    "    - Schreibt eine Funktion, in der die API angesteuert wird. Input der Funktion soll ein Suchstring (Parameter `q`) sein. Der Output soll eine Liste mit Diktionären zu den zugehörigen Artikeln (inklusive Volltexte) beinhalten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Code Übungsaufgabe 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Pagination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Bei vielen API's ist es trotz einer Erhöhung der maximalen Rückgabe an Dokumenten bei größeren Datenmengen nicht möglich, alle Treffer auf einmal abzurufen.\n",
    "- Stattdessen werden die Treffer über Pagination indexiert. Wir müssen demnach einen Weg finden, alle Pages programmatisch aufzurufen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "r = requests.get(base, params = params)\n",
    "data = r.json()\n",
    "data['response'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "nr_pages =  data['response']['pages']\n",
    "size = data['response']['pageSize'] \n",
    "page =  data['response']['currentPage']\n",
    "\n",
    "# Python String Formatting\n",
    "'Die letzte Anfrage lieferte insgesamt {} Artikel auf Seite {}, \\\n",
    "wobei insgesamt {} Pages verfügbar sind.'.format(size, page, nr_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Eine Möglichkeit um für die TheGuardian API alle Pages aufzurufen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import time # Paket um für Zeitintervalle und Datumsangaben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def get_guardian(query, \n",
    "                 hits = 200, # Wert von 200 wenn kein Input übergeben wird\n",
    "                 max_hits = 1000): # maximale Anzahl an Artikeln\n",
    "    base = 'http://content.guardianapis.com/search'\n",
    "    params = {'api-key': api_key, 'q': query, 'show-fields': 'all',\n",
    "              'page': 1, # beginn auf seite 1\n",
    "              'page-size': hits # artikel pro seite\n",
    "            \n",
    "             }\n",
    "    \n",
    "    articles = []\n",
    "    r = requests.get(base, params = params)\n",
    "    resp = r.json()['response']\n",
    "    pages = resp['pages']\n",
    "    # anzahl der pages feststellen\n",
    "    data = resp['results']\n",
    "    print('Total matches: ' + str(resp['total']))\n",
    "    print('Current page: '+ str(resp['currentPage']))\n",
    "    articles += data\n",
    "    # daten aus aktueller anfrage in liste schieben\n",
    "    \n",
    "    for p in range(2, pages + 1):\n",
    "        print(p)\n",
    "        # über alle pages iterieren\n",
    "        time.sleep(1)\n",
    "        # nach jeder anfrage eine sekunde warten\n",
    "        params['page'] = p\n",
    "        # page parameter updaten\n",
    "        r = requests.get(base, params = params)\n",
    "        resp = r.json()['response']\n",
    "        print('Current page: '+ str(resp['currentPage']))\n",
    "        data = resp['results']\n",
    "        articles += data\n",
    "        if len(articles) >= max_hits: # abbruchkriterium\n",
    "            break\n",
    "        # daten aus aktueller anfrage in liste schieben\n",
    "    return articles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "articles = get_guardian('trump', max_hits = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pprint(articles[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Die Twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Für die [Twitter API](https://developer.twitter.com/en/docs) gibt es bereits spezielle Python Packages, sodass wir nicht \"manuell\" requests erstellen müssen. \n",
    "- Ein sehr gutes Package ist `python-twitter`:\n",
    "http://python-twitter.readthedocs.io/en/latest/getting_started.html\n",
    "- Um das Paket zu nutzen muss es zunächst installiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "!pip install python-twitter --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Für den Zugang zur Twitter API werden mehrere Keys benötigt, welche erst nach der Erstellung einer Twitter App verfügbar sind (Anleitung siehe [hier](https://github.com/cschwem2er/python_data_scraping/raw/master/setup/twitter_api_access.pdf))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%cd \"D:\\datascraping\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Nach erfolgreicher Erstellung einer App empfiehlt es sich, die zugehörigen Twitter Credentials (consumer key etc.) in einer Textdatei abzulegen. Anschließend können diese wieder eingelesen werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with open('keys/twitter_api.txt', 'r') as f:\n",
    "    keys = f.read().split() # split ueber zeilenumbrueche\n",
    "\n",
    "keys[0][:10] # 10 Zeichen des consumer keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Wir speichern die Authentifizierung im Objekt `api`. Der Zusatzparameter `tweet_mode = 'extended'` ermöglicht es, die vollen Texte von Tweets abzugreifen, die länger als 140 Zeichen sind (siehe [hier](https://developer.twitter.com/en/docs/tweets/tweet-updates))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import twitter # nicht import python-twitter!\n",
    "api = twitter.Api(consumer_key = keys[0] ,\n",
    "                  consumer_secret = keys[1],\n",
    "                  access_token_key = keys[2],\n",
    "                  access_token_secret = keys[3],\n",
    "                  tweet_mode = 'extended', # tweets mit > 140 zeichen abgreifen\n",
    "                  sleep_on_rate_limit = True) # bei rate limit abwarten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Suchanfrage nach Begriffen oder Hashtags (auf Tweets aus den [vergangenen sieben Tagen](https://developer.twitter.com/en/docs/tweets/search/overview/standard.html) beschränkt):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "got = api.GetSearch('#gameofthrones', # suchbegriff\n",
    "                       count = 100) # maximale trefferanzahl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Tweets werden als spezielle Objekte gespeichert, bei denen einzelnen Attribute über Methodenaufrufe ausgelesen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "example_tweet = got[0]\n",
    "type(example_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print('id:', example_tweet.id)\n",
    "print('Text:', example_tweet.full_text) # key 'text' wenn tweet_mode != 'extended'\n",
    "print('Hashtags:', example_tweet.hashtags)\n",
    "print('Media:', example_tweet.media)\n",
    "print('Date:', example_tweet.created_at)\n",
    "print('Language:', example_tweet.lang)\n",
    "print('Retweets:', example_tweet.retweet_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Alternativ können Tweet Objekte in ein konventionelles Python Diktionär überführt werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "example_tweet.AsDict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Übungsaufgabe 3\n",
    "\n",
    "Macht euch mit der Twitter API und der Dokumentation des python-twitter Packages vertraut. Findet heraus wie man:\n",
    "   \n",
    "   - gezielt einzelne Tweets abgreift (z.B: [Audi Tweet](https://twitter.com/Audi/status/1260266468869996544))\n",
    "   - mehrere Tweets eines bestimmten Nutzers (z.B. [Jan Böhmermann](https://twitter.com/janboehm)) abgreift \n",
    "   - Die Twitter Daten in einen Pandas Datensatz überführt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Code Übungsaufgabe 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "___\n",
    "\n",
    "                \n",
    "**Kontakt: Carsten Schwemmer** (Webseite: www.carstenschwemmer.com,  Email: c.schwem2er@gmail.com)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
